# LabelCraft 2025: TF‑IDF + LinearSVC vs BERT для иерархической классификации

Репозиторий к статье на Хабре про практический кейс иерархической классификации в задаче LabelCraft 2025 (Data Fusion Contest): почему в реальном эксперименте классический стек TF‑IDF + LinearSVC оказался лучше, стабильнее и удобнее в поддержке, чем «тяжёлый» BERT‑подход и иерархический пост‑процессинг.

**Ссылка на статью:** (будет добавлена после публикации на Хабре)

## Задача

По текстовому описанию сущности (товара/объекта) нужно предсказать категорию из иерархического дерева.  
Каждая конечная метка — лист в дереве с несколькими уровнями вложенности, поэтому важны не только точные попадания, но и «близость» предсказания к истинной ветке.

Основные метрики:

- `accuracy` по листовым категориям  
- `HDA` (Hierarchical Discounted Accuracy) — иерархическая метрика, частично засчитывающая ответы, попавшие в правильную ветку

Целевой режим:  
accuracy на валидации ≳ 95 %, HDA ≳ 97 %, при этом модель должна обучаться и переобучаться в разумные сроки без тяжёлого GPU‑кластера.

## Ключевые результаты

Основные экспериментальные выводы:

- Связка **TF‑IDF + LinearSVC** даёт около **95.7 % accuracy** и **≈97.8 % HDA** на валидации, обучается быстро и не требует GPU.  
- «Тяжёлый» стек на основе **BERT‑подхода** не даёт достаточного отрыва по качеству, чтобы оправдать сложность и ресурсоёмкость пайплайна.  
- Попытки иерархического **root‑based пост‑процессинга** поверх LinearSVC обрушили метрики до **≈88 % accuracy** и **≈93 % HDA**, поэтому этот подход оставлен как честный, но неудачный эксперимент.

Главный вывод: при разумных ограничениях по ресурсам и требованиям к воспроизводимости начинать с классики (TF‑IDF + LinearSVC и им подобных) часто выгоднее, чем сразу прыгать в BERT.

## Содержимое репозитория

- `Prompt_Only_v2_iterations.ipynb`  
  Основной Colab‑ноутбук с экспериментами:
  - загрузка и подготовка данных;
  - вычисление TF‑IDF;
  - обучение LinearSVC и базовых моделей;
  - реализация HDA;
  - эксперименты с root‑based пост‑процессингом и сравнением метрик.

- `prompt_only_v2_iterations.py`  
  Экспорт основных шагов из ноутбука в `.py` для просмотра без Jupyter и интеграции в другие проекты.

Внимание: GitHub может не показывать корректный предпросмотр `.ipynb`.  
Рекомендуется **скачать ноутбук** и открыть его в Colab или локальном Jupyter.

## Как запустить

1. Откройте `Prompt_Only_v2_iterations.ipynb` в Google Colab.  
2. Убедитесь, что у сессии достаточно памяти (желательно ≥ 12 GB RAM).  
3. Последовательно выполните ячейки:
   - блок импорта и конфигурации окружения;
   - загрузка и подготовка датасета LabelCraft / Data Fusion Contest;
   - обучение и оценка моделей;
   - эксперименты с root‑based пост‑процессингом (опционально).

Датасет LabelCraft/Data Fusion Contest 2025 можно получить на платформе соревнования и разместить в ожидаемой структуре каталогов (см. комментарии в ноутбуке).

## Лицензия и ограничения

Код в этом репозитории предназначен для обучения и экспериментов.  
При использовании идей и фрагментов кода, пожалуйста, указывайте ссылку на репозиторий и исходную статью.

Внешние материалы (датасеты, формулировки задачи, тексты конкурсов) принадлежат их правообладателям и **не распространяются** через этот репозиторий; при работе с ними соблюдайте условия соответствующих платформ и лицензий.

---

